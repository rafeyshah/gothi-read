# ğŸ›ï¸ Gothi-Read

**Track B:** *OCR + Font Group Recognition (Per-Character Multi-Task)*  
**Author:** Abdul Rafey  
**Repository:** https://github.com/rafeyshah/gothi-read  

---

## ğŸš€ Overview

**Gothi-Read** is an end-to-end OCR + font-group recognition framework developed for **Pattern Recognition Lab**.  
The goal is to build and benchmark models capable of:

1. **Optical Character Recognition** â€” text transcription from scanned lines.  
2. **Font Group Recognition** â€” predicting the font category for every character.

The repository now provides:
- A verified, Unicode-safe data pipeline  
- Manifest generation and integrity checks  
- Visualization of font annotations  
- Evaluation scripts with unified model harness  
- Metrics computation for CER/WER and font accuracy

## âš™ï¸ Environment Setup

- Configured **Python 3 + PyTorch + Hugging Face + CUDA**.  
- Verified GPU availability and reproducibility across Colab and VS Code.  
- Clear modular directory layout: `scripts/`, `src/`, `notebooks/,` `runs/`.  

Main dependencies:
```bash
pip install torch torchvision torchaudio transformers jiwer pillow regex matplotlib
```

## ğŸ§¾ Dataset Handling and Validation

- `build_manifest.py` â€“ scans dataset folders to create manifest CSVs listing `.jpg`, `.txt`, and `.font` triplets.  
- `check_integrity.py` â€“ summarizes file presence & alignment health.  
- `make_test_split.py` â€“ builds reproducible test subsets.  
- Verified 100 % length alignment between text and font sequences.

**Validation Integrity Summary**
- Total lines : 4040
- Clean (ok=True) : 3827 (94.73 %)
- Missing txt : 213
- Length mismatches : 0
- âœ… 94.7 % of validation lines are clean â€” ready for evaluation.

## ğŸ”¡ Unicode-Safe Data Loader and Alignment

- Implemented in `src/icdar24.py`.  
- Uses `regex \X` to split Unicode grapheme clusters â€” accurate for ligatures and diacritics.  
- Includes two dataset classes:  
  - `LineDataset` for flat folder structures.  
  - `FlexibleLineDataset` for nested FAUBox-style layouts.  
- Strict assertions ensure `len(characters) == len(font_labels)` for every sample.  
- Optional filters for Latin-8 font groups and subset selection.

## ğŸ–¼ Visualization

`visualize_line.py` renders each line image with colored font labels per character.

**Features**
- Shows image + text with per-char color coding by font group.  
- Legend auto-maps font labels â†’ colors.  
- Trims length mismatches safely.  
- Saves visualizations to `exp/viz/`.

**Example command**
```bash
python scripts/visualize_line.py --manifest manifests/train.csv --num 8
```

## ğŸ§® Metrics Computation

- `src/metrics.py` computes:
  - **CER** (Character Error Rate)
  - **WER** (Word Error Rate)
- Uses **JiWER** for standard evaluation.  
- Normalization pipeline prepared for future expansion to font-CER.  
- Outputs aggregated JSON metrics for consistency across models.

## ğŸ§  Unified Model Evaluation Harness

`harness.py` provides a single interface to evaluate any OCR model.

**Functions**
```python
predict_lines(model_name, images) â†’ List[str]  
evaluate(text_preds, text_gts) â†’ {CER, WER, per_book, per_fontmix}
```

**Image Preprocessing**  
grayscale â†’ resize(height = 64) â†’ pad to max width

**Outputs saved to**
```
runs/<model>/<date>/
  preds.txt  
  metrics.json  
  per_line.csv  # img_id, gt, pred, CER
```

Example:
```bash
python scripts/day3_harness.py   --manifest manifests/valid.csv   --model microsoft/trocr-base-printed   --height 64   --limit 1000
```

## ğŸ“ Repository Structure

```text
gothi-read/
â”œâ”€â”€ notebooks/  
â”‚  
â”œâ”€â”€ scripts/  
â”‚   â”œâ”€â”€ build_manifest.py  
â”‚   â”œâ”€â”€ check_integrity.py  
â”‚   â”œâ”€â”€ make_test_split.py  
â”‚   â”œâ”€â”€ visualize_line.py  
â”‚   â”œâ”€â”€ build_vocab.py  
â”‚   â”œâ”€â”€ zero_shot_trocr.py  
â”‚   â”œâ”€â”€ harness.py  
â”‚  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ icdar24.py  
â”‚   â”œâ”€â”€ metrics.py  
â”‚  
â””â”€â”€ runs/  
    â””â”€â”€ microsoft_trocr-base-printed/  
```

## âœ… Achievements

- Environment and GPU setup completed  
- Dataset manifests validated (0 length mismatches)  
- Unicode-safe data loader implemented  
- Visualization utility verified  
- Metric computation (CER/WER) operational  
- Unified evaluation harness tested successfully  
- Zero-shot TrOCR baseline benchmarked with beam vs greedy  
- Decoding comparison (Day 4). **Greedy decoding** (num_beams = 1) **gave slightly better average CER/WER overall**, while **beam search** (num_beams = 5) **performed better on difficult or ambiguous lines.**  
- Zero-shot **PaddleOCR (PP-OCRv4 English)** baseline benchmarked on the same validation split.

## ğŸ”œ Next Steps

- Add font-classification head to OCR encoder for multi-task learning.  
- Extend PaddleOCR experiments and integrate additional models: Donut, MMOCR, docTR.  
- Benchmark all models on the same validation split.  
- Compute joint **text CER + font-CER**.  
- Build a leaderboard under `/runs/` for cross-model comparisons.

## ğŸ Summary

**Gothi-Read** now includes a validated data pipeline, visualization system, and unified model evaluation framework.  
All data integrity, alignment, and evaluation steps are complete.  
The project is ready for multi-model benchmarking and fine-tuning experiments for Pattern Recognition Lab.

Current zero-shot OCR baselines on the validation split:

| run           | CER       | WER       |
|---------------|-----------|-----------|
| **Paddle-OCRv4**     | **0.203298** | **0.755115** |
| trocr-greedy  | 1.255461  | 1.598408  |
| trocr-beam    | 1.361015  | 1.732157  |

PaddleOCR (PP-OCRv4, English, detection disabled, line-crop recognizer) currently achieves the best CER/WER among the evaluated models.
