{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dcf40f5f",
      "metadata": {
        "id": "dcf40f5f"
      },
      "source": [
        "# 01. Environment & Repo Setup (GothiRead)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4251a36c",
      "metadata": {
        "id": "4251a36c"
      },
      "source": [
        "Run each cell in order. If a step fails, re-run the cell after fixing the issue."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-Jb26GSvcT5",
        "outputId": "2116748d-fb6a-4230-9a52-9df6fe3b71b8"
      },
      "id": "n-Jb26GSvcT5",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "845cf48e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "845cf48e",
        "outputId": "a9f729f9-4d3e-4f8f-8095-ccb50382dda2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "PyTorch version (pre): 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "import torch, platform, sys\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"PyTorch version (pre):\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "52c1ae4a",
      "metadata": {
        "id": "52c1ae4a"
      },
      "outputs": [],
      "source": [
        "# Install core packages (HF + metrics). Re-run if Colab restarts.\n",
        "!pip -q install -U pip\n",
        "!pip -q install -U transformers accelerate datasets evaluate jiwer Pillow regex editdistance sentencepiece timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c07f67a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c07f67a3",
        "outputId": "eed21e30-5870-4cb8-cd64-18ad8377e136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version (post): 2.8.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# (Optional) Install a stable PyTorch if missing. On Colab this is usually preinstalled.\n",
        "# You can uncomment and run if needed:\n",
        "# !pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "import torch\n",
        "print(\"PyTorch version (post):\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e8bbca7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8bbca7c",
        "outputId": "fa8bd9a2-d44c-46ab-f823-41144c1da0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers: 4.57.0\n",
            "Ready.\n"
          ]
        }
      ],
      "source": [
        "# Verify imports\n",
        "import transformers, datasets, jiwer, PIL, regex, editdistance, sentencepiece, timm\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "print(\"Transformers:\", transformers.__version__)\n",
        "print(\"Ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cf34adf7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf34adf7",
        "outputId": "e2dbeacf-80db-427a-8fc3-756cae624af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project folders ready at /content/drive/MyDrive/GothiRead\n"
          ]
        }
      ],
      "source": [
        "# Create folders for data and experiments (idempotent)\n",
        "import os\n",
        "base = \"/content/drive/MyDrive/GothiRead\"\n",
        "subdirs = [\"src/data\", \"src/eval\", \"src/models\", \"scripts\", \"data/train\", \"data/val\", \"data/test_public\", \"exp\"]\n",
        "for sd in subdirs:\n",
        "    os.makedirs(os.path.join(base, sd), exist_ok=True)\n",
        "print(\"Project folders ready at\", base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8333767b",
      "metadata": {
        "id": "8333767b"
      },
      "outputs": [],
      "source": [
        "# Copy scaffold from the uploaded zip (if you uploaded it) or from Drive.\n",
        "# If you downloaded the provided zip, upload it to Colab and run:\n",
        "# from google.colab import files\n",
        "# files.upload()  # then select 'icdar24-multifont.zip'\n",
        "# import zipfile, os\n",
        "# with zipfile.ZipFile('icdar24-multifont.zip', 'r') as z:\n",
        "#     z.extractall('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58798f18",
      "metadata": {
        "id": "58798f18"
      },
      "outputs": [],
      "source": [
        "# (Optional) Mount Google Drive to persist data/experiments\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dd2a386",
      "metadata": {
        "id": "2dd2a386"
      },
      "source": [
        "## Optional: Install PaddleOCR (CPU) â€” safer on Day 1\n",
        "GPU wheels can be tricky; switch to GPU later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "de83cad1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de83cad1",
        "outputId": "11e1c2d0-2b19-4634-fefd-393b03fc86aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
            "  warnings.warn(warning_message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paddle: 3.0.0\n"
          ]
        }
      ],
      "source": [
        "# CPU PaddleOCR install (safe default)\n",
        "!pip -q install paddlepaddle==3.0.0 paddleocr\n",
        "import paddle, paddleocr\n",
        "print(\"Paddle:\", paddle.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66fe42f5",
      "metadata": {
        "id": "66fe42f5"
      },
      "source": [
        "## Quick zero-shot sanity check for TrOCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eacbe356",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eacbe356",
        "outputId": "2293bf24-4305-4303-d601-92df2682e496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/line.jpg\n"
          ]
        }
      ],
      "source": [
        "# Download a tiny demo image or place your line image at /content/line.jpg\n",
        "# For now, we'll generate a blank image as a placeholder.\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "img = Image.new('RGB', (640, 96), color='white')\n",
        "draw = ImageDraw.Draw(img)\n",
        "draw.text((10, 30), \"Demo Line\", fill='black')\n",
        "img.save('/content/line.jpg')\n",
        "print(\"Saved /content/line.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9b9807a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b9807a7",
        "outputId": "5c1aebe3-d144-4263-db54-b6ef64c75fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: BANDAR AND ONCLUSIVE ONCLUSIVE OF RECEIPT FOR\n"
          ]
        }
      ],
      "source": [
        "# Zero-shot TrOCR test (printed)\n",
        "from PIL import Image\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "proc = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\").eval()\n",
        "img = Image.open(\"/content/line.jpg\").convert(\"RGB\")\n",
        "inputs = proc(images=img, return_tensors=\"pt\")\n",
        "out_ids = model.generate(**inputs, max_length=64)\n",
        "text = proc.batch_decode(out_ids, skip_special_tokens=True)[0]\n",
        "print(\"Prediction:\", text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}